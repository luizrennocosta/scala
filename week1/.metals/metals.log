2020.08.23 20:14:05 INFO  started: Metals version 0.9.3 in workspace '/home/cyfer/scala/week1' for client vscode.
2020.08.23 20:14:05 INFO  time: initialize in 0.26s
2020.08.23 20:14:06 WARN  no build tool detected in workspace '/home/cyfer/scala/week1'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2020.08.23 20:14:06 INFO  no build target: using presentation compiler with only scala-library
2020.08.23 20:14:08 WARN  no build target for: /home/cyfer/scala/week1/src/main/week1.scala
2020.08.23 20:14:25 WARN  no build target for: /home/cyfer/scala/week1/src/main/week1.scala
2020.08.23 20:14:46 WARN  no build tool detected in workspace '/home/cyfer/scala/week1'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2020.08.23 20:15:35 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals2771968559757510680/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:15:37 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:15:38 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:15:38 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:15:43 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:15:43 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:15:44 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:15:44 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:15:48 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:15:48 INFO  [success] Total time: 4 s, completed Aug 23, 2020 8:15:48 PM
2020.08.23 20:15:48 INFO  [info] set current project to week1 (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:15:49 INFO  [success] Generated .bloop/week1-test.json
2020.08.23 20:15:49 INFO  [success] Generated .bloop/week1.json
2020.08.23 20:15:49 INFO  [success] Total time: 1 s, completed Aug 23, 2020 8:15:50 PM
2020.08.23 20:15:49 INFO  build tool exit: 0
2020.08.23 20:15:50 INFO  time: ran 'sbt bloopInstall' in 15s
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher160029474919596598/bsp.socket'...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
No server running at 127.0.0.1:8212, let's fire one...
Resolving ch.epfl.scala:bloop-frontend_2.12:1.4.3-23-550c6c0a...
Starting bloop server at 127.0.0.1:8212...
Attempting a connection to the server...
Attempting a connection to the server...
Attempting a connection to the server...
Attempting a connection to the server...
[0m[32m[D][0m Loading 2 projects from '/home/cyfer/scala/week1/.bloop'...
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1-test.json'
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1.json'
[0m[32m[D][0m Cache miss for scala instance org.scala-lang:scala-compiler:2.12.10.
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/jansi.jar
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/jline.jar
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/scala-compiler.jar
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/scala-library.jar
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/scala-reflect.jar
[0m[32m[D][0m   => /home/cyfer/.sbt/boot/scala-2.12.10/lib/scala-xml_2.12.jar
[0m[32m[D][0m Missing analysis file for project 'week1'
[0m[32m[D][0m Missing analysis file for project 'week1-test'
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher160029474919596598/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher160029474919596598/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:16:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher5083185023052312517/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher5083185023052312517/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher5083185023052312517/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:16:09 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:16:09 INFO  time: connected to build server in 19s
2020.08.23 20:16:09 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:16:09 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:16:11 INFO  time: indexed workspace in 1.53s
2020.08.23 20:16:11 WARN  no build target for: /home/cyfer/scala/week1/src/main/week1.scala
2020.08.23 20:16:11 INFO  skipping build import with status 'Installed'
2020.08.23 20:17:25 WARN  no build target for: /home/cyfer/scala/week1/src/main/week1.scala
Aug 23, 2020 8:21:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 79
2020.08.23 20:21:25 INFO  compiling week1 (1 scala source)
2020.08.23 20:21:34 INFO  time: compiled week1 in 9.21s
2020.08.23 20:21:34 INFO  compiling week1 (1 scala source)
2020.08.23 20:21:34 INFO  time: compiled week1 in 60ms
2020.08.23 20:22:31 INFO  compiling week1 (1 scala source)
2020.08.23 20:22:31 INFO  time: compiled week1 in 42ms
2020.08.23 20:24:04 INFO  compiling week1 (1 scala source)
2020.08.23 20:24:04 INFO  time: compiled week1 in 44ms
2020.08.23 20:24:30 INFO  skipping build import with status 'Installed'
2020.08.23 20:26:19 INFO  compiling week1 (1 scala source)
2020.08.23 20:26:19 INFO  time: compiled week1 in 38ms
2020.08.23 20:26:37 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:37 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:37 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:37 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:39 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:39 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:39 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:41 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:41 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:41 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:43 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:44 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:44 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:44 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:46 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:26:46 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:06 INFO  compiling week1 (1 scala source)
2020.08.23 20:27:06 INFO  time: compiled week1 in 45ms
2020.08.23 20:27:08 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:08 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:10 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:10 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:10 ERROR code navigation does not work for the file '/home/cyfer/scala/week1/src/main/scala/week1.scala' because the SemanticDB file '/home/cyfer/scala/week1/.bloop/week1/bloop-bsp-clients-classes/classes-Metals-JUqtnwXTQWaVZ5PjqYS_4A==/META-INF/semanticdb/src/main/scala/week1.scala.semanticdb' doesn't exist. There can be many reasons for this error. 
2020.08.23 20:27:45 INFO  compiling week1 (1 scala source)
2020.08.23 20:27:45 INFO  time: compiled week1 in 39ms
2020.08.23 20:28:10 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals2975188977479302547/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:28:12 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:28:12 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:28:13 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:28:13 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:28:13 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:28:16 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:28:16 INFO  [success] Total time: 2 s, completed Aug 23, 2020 8:28:16 PM
2020.08.23 20:28:17 INFO  [info] loading settings for project week1 from build.sbt ...
2020.08.23 20:28:17 INFO  [info] set current project to week1 (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:28:17 INFO  [success] Generated .bloop/week1-test.json
2020.08.23 20:28:17 INFO  [success] Generated .bloop/week1.json
2020.08.23 20:28:17 INFO  [success] Total time: 0 s, completed Aug 23, 2020 8:28:18 PM
2020.08.23 20:28:18 INFO  build tool exit: 0
2020.08.23 20:28:18 INFO  time: ran 'sbt bloopInstall' in 8.45s
2020.08.23 20:28:18 INFO  disconnected: build server
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher6035801917096205624/bsp.socket'...
Waiting for the bsp connection to come up...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Loading 2 projects from '/home/cyfer/scala/week1/.bloop'...
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1-test.json'
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1.json'
[0m[32m[D][0m Configured SemanticDB in projects 'week1', 'week1-test'
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher6035801917096205624/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher6035801917096205624/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:28:18 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher6337722216340793278/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher6337722216340793278/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher6337722216340793278/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:28:19 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:28:19 INFO  time: connected to build server in 0.14s
2020.08.23 20:28:19 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:28:18 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:28:18 INFO  time: indexed workspace in 0.29s
2020.08.23 20:28:19 INFO  compiling week1 (1 scala source)
2020.08.23 20:28:19 INFO  time: compiled week1 in 55ms
2020.08.23 20:29:50 INFO  compiling week1 (1 scala source)
2020.08.23 20:29:50 INFO  time: compiled week1 in 63ms
2020.08.23 20:30:41 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals7949706998591843322/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:30:43 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:30:43 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:30:44 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:30:44 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:30:44 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:30:46 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:30:46 INFO  [success] Total time: 1 s, completed Aug 23, 2020 8:30:46 PM
2020.08.23 20:30:48 INFO  [info] loading settings for project week1 from build.sbt ...
2020.08.23 20:30:48 INFO  [info] set current project to Simple Project (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:31:03 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:31:07 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:31:07 INFO  [success] Generated .bloop/week1-test.json
2020.08.23 20:31:07 INFO  [success] Generated .bloop/week1.json
2020.08.23 20:31:07 INFO  [success] Total time: 18 s, completed Aug 23, 2020 8:31:07 PM
2020.08.23 20:31:07 INFO  build tool exit: 0
2020.08.23 20:31:07 INFO  time: ran 'sbt bloopInstall' in 25s
2020.08.23 20:31:07 INFO  disconnected: build server
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher7986483036096585259/bsp.socket'...
Waiting for the bsp connection to come up...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Loading 2 projects from '/home/cyfer/scala/week1/.bloop'...
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1.json'
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1-test.json'
[0m[32m[D][0m Cache miss for scala instance org.scala-lang:scala-compiler:2.10.4.
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/fusesource/jansi/jansi/1.4/jansi-1.4.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/jline/2.10.4/jline-2.10.4.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.10.4/scala-compiler-2.10.4.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar
[0m[32m[D][0m Skipped configuration of SemanticDB in unsupported 2.10.4 projects
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher7986483036096585259/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher7986483036096585259/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:31:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher7286994736533772584/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher7286994736533772584/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher7286994736533772584/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:31:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:31:07 INFO  time: connected to build server in 0.1s
2020.08.23 20:31:07 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:31:07 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:31:08 INFO  time: indexed workspace in 1.36s
2020.08.23 20:31:08 WARN  unsupported Scala 2.10.4
2020.08.23 20:31:08 INFO  compiling week1 (1 scala source)
2020.08.23 20:31:18 INFO  time: compiled week1 in 10s
2020.08.23 20:33:11 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals3988919112933143772/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:33:13 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:33:13 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:33:14 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:33:14 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:33:14 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:33:16 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:33:16 INFO  [success] Total time: 1 s, completed Aug 23, 2020 8:33:16 PM
2020.08.23 20:33:18 INFO  [info] loading settings for project week1 from build.sbt ...
2020.08.23 20:33:18 INFO  [info] set current project to Simple Project (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:33:19 INFO  [warn] 
2020.08.23 20:33:19 INFO  [warn] 	Note: Unresolved dependencies path:
2020.08.23 20:33:19 INFO  [error] sbt.librarymanagement.ResolveException: Error downloading org.apache.spark:spark-core_2.12:1.2.0
2020.08.23 20:33:19 INFO  [error]   Not found
2020.08.23 20:33:19 INFO  [error]   Not found
2020.08.23 20:33:19 INFO  [error]   not found: /home/cyfer/.ivy2/local/org.apache.spark/spark-core_2.12/1.2.0/ivys/ivy.xml
2020.08.23 20:33:19 INFO  [error]   not found: https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/1.2.0/spark-core_2.12-1.2.0.pom
2020.08.23 20:33:19 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.unresolvedWarningOrThrow(CoursierDependencyResolution.scala:249)
2020.08.23 20:33:19 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.$anonfun$update$35(CoursierDependencyResolution.scala:218)
2020.08.23 20:33:19 INFO  [error] 	at scala.util.Either$LeftProjection.map(Either.scala:573)
2020.08.23 20:33:19 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.update(CoursierDependencyResolution.scala:218)
2020.08.23 20:33:19 INFO  [error] 	at sbt.librarymanagement.DependencyResolution.update(DependencyResolution.scala:60)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.resolve$1(LibraryManagement.scala:52)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$12(LibraryManagement.scala:102)
2020.08.23 20:33:19 INFO  [error] 	at sbt.util.Tracked$.$anonfun$lastOutput$1(Tracked.scala:69)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$20(LibraryManagement.scala:115)
2020.08.23 20:33:19 INFO  [error] 	at scala.util.control.Exception$Catch.apply(Exception.scala:228)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11(LibraryManagement.scala:115)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11$adapted(LibraryManagement.scala:96)
2020.08.23 20:33:19 INFO  [error] 	at sbt.util.Tracked$.$anonfun$inputChanged$1(Tracked.scala:150)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.LibraryManagement$.cachedUpdate(LibraryManagement.scala:129)
2020.08.23 20:33:19 INFO  [error] 	at sbt.Classpaths$.$anonfun$updateTask0$5(Defaults.scala:2950)
2020.08.23 20:33:19 INFO  [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62)
2020.08.23 20:33:19 INFO  [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67)
2020.08.23 20:33:19 INFO  [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:281)
2020.08.23 20:33:19 INFO  [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)
2020.08.23 20:33:19 INFO  [error] 	at sbt.Execute.work(Execute.scala:290)
2020.08.23 20:33:19 INFO  [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:281)
2020.08.23 20:33:19 INFO  [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
2020.08.23 20:33:19 INFO  [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
2020.08.23 20:33:19 INFO  [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020.08.23 20:33:19 INFO  [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
2020.08.23 20:33:19 INFO  [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020.08.23 20:33:19 INFO  [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
2020.08.23 20:33:19 INFO  [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
2020.08.23 20:33:19 INFO  [error] 	at java.lang.Thread.run(Thread.java:748)
2020.08.23 20:33:19 INFO  [error] (update) sbt.librarymanagement.ResolveException: Error downloading org.apache.spark:spark-core_2.12:1.2.0
2020.08.23 20:33:19 INFO  [error]   Not found
2020.08.23 20:33:19 INFO  [error]   Not found
2020.08.23 20:33:19 INFO  [error]   not found: /home/cyfer/.ivy2/local/org.apache.spark/spark-core_2.12/1.2.0/ivys/ivy.xml
2020.08.23 20:33:19 INFO  [error]   not found: https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/1.2.0/spark-core_2.12-1.2.0.pom
2020.08.23 20:33:19 INFO  [error] Total time: 1 s, completed Aug 23, 2020 8:33:19 PM
2020.08.23 20:33:19 INFO  build tool exit: 1
2020.08.23 20:33:19 INFO  time: ran 'sbt bloopInstall' in 7.98s
2020.08.23 20:33:19 INFO  disconnected: build server
2020.08.23 20:33:19 ERROR sbt command failed: /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals3988919112933143772/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher5942915288370423381/bsp.socket'...
Waiting for the bsp connection to come up...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher5942915288370423381/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher5942915288370423381/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:33:19 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher4472809534939106595/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher4472809534939106595/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher4472809534939106595/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:33:19 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:33:19 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:33:19 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:33:19 INFO  time: indexed workspace in 0.57s
2020.08.23 20:33:19 WARN  unsupported Scala 2.10.4
2020.08.23 20:35:57 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals1689849781849323225/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:35:59 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:35:59 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:36:00 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:36:00 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:36:00 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:36:02 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:36:02 INFO  [success] Total time: 1 s, completed Aug 23, 2020 8:36:02 PM
2020.08.23 20:36:02 INFO  [info] loading settings for project week1 from build.sbt ...
2020.08.23 20:36:02 INFO  [info] set current project to Simple Project (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:36:04 INFO  [warn] 
2020.08.23 20:36:04 INFO  [warn] 	Note: Unresolved dependencies path:
2020.08.23 20:36:04 INFO  [error] sbt.librarymanagement.ResolveException: Error downloading org.apache.spark:spark-core_2.12:1.2.0
2020.08.23 20:36:04 INFO  [error]   Not found
2020.08.23 20:36:04 INFO  [error]   Not found
2020.08.23 20:36:04 INFO  [error]   not found: /home/cyfer/.ivy2/local/org.apache.spark/spark-core_2.12/1.2.0/ivys/ivy.xml
2020.08.23 20:36:04 INFO  [error]   not found: https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/1.2.0/spark-core_2.12-1.2.0.pom
2020.08.23 20:36:04 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.unresolvedWarningOrThrow(CoursierDependencyResolution.scala:249)
2020.08.23 20:36:04 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.$anonfun$update$35(CoursierDependencyResolution.scala:218)
2020.08.23 20:36:04 INFO  [error] 	at scala.util.Either$LeftProjection.map(Either.scala:573)
2020.08.23 20:36:04 INFO  [error] 	at lmcoursier.CoursierDependencyResolution.update(CoursierDependencyResolution.scala:218)
2020.08.23 20:36:04 INFO  [error] 	at sbt.librarymanagement.DependencyResolution.update(DependencyResolution.scala:60)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.resolve$1(LibraryManagement.scala:52)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$12(LibraryManagement.scala:102)
2020.08.23 20:36:04 INFO  [error] 	at sbt.util.Tracked$.$anonfun$lastOutput$1(Tracked.scala:69)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$20(LibraryManagement.scala:115)
2020.08.23 20:36:04 INFO  [error] 	at scala.util.control.Exception$Catch.apply(Exception.scala:228)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11(LibraryManagement.scala:115)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11$adapted(LibraryManagement.scala:96)
2020.08.23 20:36:04 INFO  [error] 	at sbt.util.Tracked$.$anonfun$inputChanged$1(Tracked.scala:150)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.LibraryManagement$.cachedUpdate(LibraryManagement.scala:129)
2020.08.23 20:36:04 INFO  [error] 	at sbt.Classpaths$.$anonfun$updateTask0$5(Defaults.scala:2950)
2020.08.23 20:36:04 INFO  [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62)
2020.08.23 20:36:04 INFO  [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67)
2020.08.23 20:36:04 INFO  [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:281)
2020.08.23 20:36:04 INFO  [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)
2020.08.23 20:36:04 INFO  [error] 	at sbt.Execute.work(Execute.scala:290)
2020.08.23 20:36:04 INFO  [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:281)
2020.08.23 20:36:04 INFO  [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)
2020.08.23 20:36:04 INFO  [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37)
2020.08.23 20:36:04 INFO  [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020.08.23 20:36:04 INFO  [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
2020.08.23 20:36:04 INFO  [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2020.08.23 20:36:04 INFO  [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
2020.08.23 20:36:04 INFO  [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
2020.08.23 20:36:04 INFO  [error] 	at java.lang.Thread.run(Thread.java:748)
2020.08.23 20:36:04 INFO  [error] (update) sbt.librarymanagement.ResolveException: Error downloading org.apache.spark:spark-core_2.12:1.2.0
2020.08.23 20:36:04 INFO  [error]   Not found
2020.08.23 20:36:04 INFO  [error]   Not found
2020.08.23 20:36:04 INFO  [error]   not found: /home/cyfer/.ivy2/local/org.apache.spark/spark-core_2.12/1.2.0/ivys/ivy.xml
2020.08.23 20:36:04 INFO  [error]   not found: https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/1.2.0/spark-core_2.12-1.2.0.pom
2020.08.23 20:36:04 INFO  [error] Total time: 1 s, completed Aug 23, 2020 8:36:04 PM
2020.08.23 20:36:04 INFO  build tool exit: 1
2020.08.23 20:36:04 INFO  time: ran 'sbt bloopInstall' in 7.05s
2020.08.23 20:36:04 INFO  disconnected: build server
2020.08.23 20:36:04 ERROR sbt command failed: /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals1689849781849323225/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher7682400807707927877/bsp.socket'...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
Waiting for the bsp connection to come up...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher7682400807707927877/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher7682400807707927877/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:36:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher4618221228730222795/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher4618221228730222795/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher4618221228730222795/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:36:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:36:04 INFO  time: connected to build server in 0.14s
2020.08.23 20:36:04 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:36:05 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:36:05 INFO  time: indexed workspace in 0.57s
2020.08.23 20:36:05 WARN  unsupported Scala 2.10.4
2020.08.23 20:38:18 INFO  running '/usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals865036880068682901/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2020.08.23 20:38:19 INFO  [info] welcome to sbt 1.3.13 (Private Build Java 1.8.0_265)
2020.08.23 20:38:19 INFO  [info] loading settings for project week1-build-build from metals.sbt ...
2020.08.23 20:38:21 INFO  [info] loading project definition from /home/cyfer/scala/week1/project/project
2020.08.23 20:38:21 INFO  [info] loading settings for project week1-build from metals.sbt ...
2020.08.23 20:38:21 INFO  [info] loading project definition from /home/cyfer/scala/week1/project
2020.08.23 20:38:23 INFO  [success] Generated .bloop/week1-build.json
2020.08.23 20:38:23 INFO  [success] Total time: 1 s, completed Aug 23, 2020 8:38:23 PM
2020.08.23 20:38:24 INFO  [info] loading settings for project week1 from build.sbt ...
2020.08.23 20:38:24 INFO  [info] set current project to Simple Project (in build file:/home/cyfer/scala/week1/)
2020.08.23 20:38:48 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:38:55 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2020.08.23 20:38:55 INFO  [success] Generated .bloop/week1-test.json
2020.08.23 20:38:55 INFO  [success] Generated .bloop/week1.json
2020.08.23 20:38:55 INFO  [success] Total time: 31 s, completed Aug 23, 2020 8:38:55 PM
2020.08.23 20:38:55 INFO  build tool exit: 0
2020.08.23 20:38:55 INFO  time: ran 'sbt bloopInstall' in 37s
2020.08.23 20:38:55 INFO  disconnected: build server
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher9149575087518414077/bsp.socket'...
Waiting for the bsp connection to come up...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
Waiting for the bsp connection to come up...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Loading 2 projects from '/home/cyfer/scala/week1/.bloop'...
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1-test.json'
[0m[32m[D][0m Loading project from '/home/cyfer/scala/week1/.bloop/week1.json'
[0m[32m[D][0m Cache miss for scala instance org.scala-lang:scala-compiler:2.12.12.
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/jline/jline/2.14.6/jline-2.14.6.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/fusesource/jansi/jansi/1.12/jansi-1.12.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.12.12/scala-compiler-2.12.12.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.12/scala-library-2.12.12.jar
[0m[32m[D][0m   => /home/cyfer/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.12/scala-reflect-2.12.12.jar
[0m[32m[D][0m Resolving org.scalameta:semanticdb-scalac_2.12.12:4.3.20
[0m[32m[D][0m Configured SemanticDB in projects 'week1', 'week1-test'
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher9149575087518414077/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher9149575087518414077/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:38:58 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
Starting the bsp launcher for bloop...
Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher5569400105415727896/bsp.socket'...
Waiting for the bsp connection to come up...
[0m[32m[D][0m Loading workspace settings from bloop.settings.json
[0m[32m[D][0m Waiting for a connection at local:///tmp/bsp-launcher5569400105415727896/bsp.socket...
The server is listening for incoming connections at local:///tmp/bsp-launcher5569400105415727896/bsp.socket...
Starting thread that pumps stdin and redirects it to the bsp server...
Starting thread that pumps server stdout and redirects it to the client stdout...
2020.08.23 20:38:58 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/bsp.trace.json
2020.08.23 20:38:58 INFO  time: connected to build server in 2.89s
2020.08.23 20:38:58 INFO  Connected to Build server v1.4.3-23-550c6c0a
2020.08.23 20:38:58 WARN  Could not find java sources in None. Java symbols will not be available.
2020.08.23 20:38:59 INFO  time: indexed workspace in 1.15s
2020.08.23 20:39:04 INFO  compiling week1 (1 scala source)
2020.08.23 20:39:14 INFO  time: compiled week1 in 9.61s
2020.08.23 20:40:39 INFO  skipping build import with status 'Installed'
2020.08.23 20:41:18 INFO  compiling week1 (1 scala source)
2020.08.23 20:41:18 INFO  time: compiled week1 in 91ms
2020.08.23 20:41:53 INFO  compiling week1 (1 scala source)
2020.08.23 20:41:53 INFO  time: compiled week1 in 0.55s
2020.08.23 20:42:56 INFO  compiling week1 (1 scala source)
2020.08.23 20:42:56 INFO  time: compiled week1 in 0.56s
2020.08.23 20:43:53 INFO  compiling week1 (1 scala source)
2020.08.23 20:43:53 INFO  time: compiled week1 in 0.56s
2020.08.23 20:44:26 INFO  compiling week1 (1 scala source)
2020.08.23 20:44:26 INFO  time: compiled week1 in 0.49s
2020.08.23 20:44:52 INFO  compiling week1 (1 scala source)
2020.08.23 20:44:52 INFO  time: compiled week1 in 0.53s
2020.08.23 20:46:01 INFO  compiling week1 (1 scala source)
2020.08.23 20:46:01 INFO  time: compiled week1 in 0.47s
2020.08.23 20:48:47 INFO  compiling week1 (1 scala source)
2020.08.23 20:48:47 INFO  time: compiled week1 in 0.72s
2020.08.23 20:49:59 INFO  compiling week1 (1 scala source)
2020.08.23 20:49:59 INFO  time: compiled week1 in 0.89s
2020.08.23 20:52:08 INFO  compiling week1 (1 scala source)
2020.08.23 20:52:08 INFO  time: compiled week1 in 0.11s
2020.08.23 20:52:38 INFO  compiling week1 (1 scala source)
2020.08.23 20:52:38 INFO  time: compiled week1 in 77ms
2020.08.23 20:54:42 INFO  compiling week1 (1 scala source)
2020.08.23 20:54:42 INFO  time: compiled week1 in 67ms
2020.08.23 20:55:19 INFO  compiling week1 (1 scala source)
2020.08.23 20:55:19 INFO  time: compiled week1 in 63ms
2020.08.23 20:58:05 INFO  compiling week1 (1 scala source)
2020.08.23 20:58:05 INFO  time: compiled week1 in 61ms
2020.08.23 20:59:08 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:08 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:08 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:08 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:09 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:09 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:7:1: stale bloop error: illegal start of declaration (possible cause: missing `=' in front of current method body)
_       
^
2020.08.23 20:59:34 INFO  compiling week1 (1 scala source)
2020.08.23 20:59:34 INFO  time: compiled week1 in 0.1s
2020.08.23 21:00:11 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:10:40: stale bloop error: type mismatch;
 found   : (x$1: String)Array[String] <and> (x$1: String, x$2: Int)Array[String]
 required: TraversableOnce[?]
    var workds = input.flatMap(line => line.split)
                                       ^^^^^^^^^^
2020.08.23 21:00:11 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:10:40: stale bloop error: type mismatch;
 found   : (x$1: String)Array[String] <and> (x$1: String, x$2: Int)Array[String]
 required: TraversableOnce[?]
    var workds = input.flatMap(line => line.split)
                                       ^^^^^^^^^^
2020.08.23 21:00:11 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:10:40: stale bloop error: type mismatch;
 found   : (x$1: String)Array[String] <and> (x$1: String, x$2: Int)Array[String]
 required: TraversableOnce[?]
    var workds = input.flatMap(line => line.split)
                                       ^^^^^^^^^^
2020.08.23 21:00:11 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:10:40: stale bloop error: type mismatch;
 found   : (x$1: String)Array[String] <and> (x$1: String, x$2: Int)Array[String]
 required: TraversableOnce[?]
    var workds = input.flatMap(line => line.split)
                                       ^^^^^^^^^^
2020.08.23 21:00:26 INFO  compiling week1 (1 scala source)
2020.08.23 21:00:26 INFO  time: compiled week1 in 0.48s
2020.08.23 21:02:50 INFO  compiling week1 (1 scala source)
2020.08.23 21:02:50 INFO  time: compiled week1 in 59ms
2020.08.23 21:02:58 INFO  compiling week1 (1 scala source)
2020.08.23 21:02:58 INFO  time: compiled week1 in 77ms
2020.08.23 21:03:05 INFO  compiling week1 (1 scala source)
2020.08.23 21:03:05 INFO  time: compiled week1 in 55ms
2020.08.23 21:04:39 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:11:1: stale bloop error: illegal start of simple expression
}
^
2020.08.23 21:04:39 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:11:1: stale bloop error: illegal start of simple expression
}
^
2020.08.23 21:06:29 INFO  compiling week1 (1 scala source)
2020.08.23 21:06:29 INFO  time: compiled week1 in 0.42s
2020.08.23 21:06:36 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:06:36 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:06:36 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:06:36 INFO  Listening for transport dt_socket at address: 35485
2020.08.23 21:06:36 INFO  Trying to attach to remote debuggee VM localhost:35485 .
2020.08.23 21:06:36 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:06:36 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:06:36 ERROR 20/08/23 21:06:37 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:06:36 ERROR 20/08/23 21:06:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:06:38 ERROR 20/08/23 21:06:38 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:06:38 ERROR 20/08/23 21:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:06:38 ERROR 20/08/23 21:06:38 ERROR SparkContext: Error initializing SparkContext.
2020.08.23 21:06:38 ERROR org.apache.spark.SparkException: A master URL must be set in your configuration
2020.08.23 21:06:38 ERROR 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:380)
2020.08.23 21:06:38 ERROR 	at WordCount$.delayedEndpoint$WordCount$1(week1.scala:7)
2020.08.23 21:06:38 ERROR 	at WordCount$delayedInit$body.apply(week1.scala:4)
2020.08.23 21:06:38 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2020.08.23 21:06:38 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2020.08.23 21:06:38 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2020.08.23 21:06:38 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2020.08.23 21:06:38 ERROR 	at scala.collection.immutable.List.foreach(List.scala:431)
2020.08.23 21:06:38 ERROR 	at scala.App.main(App.scala:80)
2020.08.23 21:06:38 ERROR 	at scala.App.main$(App.scala:78)
2020.08.23 21:06:38 ERROR 	at WordCount$.main(week1.scala:4)
2020.08.23 21:06:38 ERROR 	at WordCount.main(week1.scala)
2020.08.23 21:06:38 ERROR 20/08/23 21:06:38 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:06:38 ERROR Exception in thread "main" org.apache.spark.SparkException: A master URL must be set in your configuration
2020.08.23 21:06:38 ERROR 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:380)
2020.08.23 21:06:38 ERROR 	at WordCount$.delayedEndpoint$WordCount$1(week1.scala:7)
2020.08.23 21:06:38 ERROR 	at WordCount$delayedInit$body.apply(week1.scala:4)
2020.08.23 21:06:38 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2020.08.23 21:06:38 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2020.08.23 21:06:38 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2020.08.23 21:06:38 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2020.08.23 21:06:38 ERROR 	at scala.collection.immutable.List.foreach(List.scala:431)
2020.08.23 21:06:38 ERROR 	at scala.App.main(App.scala:80)
2020.08.23 21:06:38 ERROR 	at scala.App.main$(App.scala:78)
2020.08.23 21:06:38 ERROR 	at WordCount$.main(week1.scala:4)
2020.08.23 21:06:38 ERROR 	at WordCount.main(week1.scala)
2020.08.23 21:06:38 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:08:29 INFO  compiling week1 (1 scala source)
2020.08.23 21:08:29 INFO  time: compiled week1 in 57ms
2020.08.23 21:08:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:6:63: stale bloop error: illegal start of simple expression
    val conf = new SparkConf().setAppName("Abusei").setMaster(...)
                                                              ^
2020.08.23 21:08:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:11:1: stale bloop error: ')' expected but '}' found.
}
^
2020.08.23 21:08:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:6:63: stale bloop error: illegal start of simple expression
    val conf = new SparkConf().setAppName("Abusei").setMaster(...)
                                                              ^
2020.08.23 21:08:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:11:1: stale bloop error: ')' expected but '}' found.
}
^
2020.08.23 21:08:49 INFO  compiling week1 (1 scala source)
2020.08.23 21:08:49 INFO  time: compiled week1 in 0.46s
2020.08.23 21:08:50 INFO  compiling week1 (1 scala source)
2020.08.23 21:08:50 INFO  time: compiled week1 in 79ms
2020.08.23 21:08:58 INFO  compiling week1 (1 scala source)
2020.08.23 21:08:58 INFO  time: compiled week1 in 0.48s
2020.08.23 21:09:00 INFO  compiling week1 (1 scala source)
2020.08.23 21:09:00 INFO  time: compiled week1 in 0.45s
2020.08.23 21:09:25 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:09:25 INFO  Listening for transport dt_socket at address: 37579
2020.08.23 21:09:25 INFO  compiling week1 (1 scala source)
2020.08.23 21:09:25 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:09:26 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:09:25 INFO  Trying to attach to remote debuggee VM localhost:37579 .
2020.08.23 21:09:25 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:09:25 INFO  time: compiled week1 in 0.48s
2020.08.23 21:09:26 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:09:26 ERROR 20/08/23 21:09:26 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:09:26 ERROR 20/08/23 21:09:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:09:27 ERROR 20/08/23 21:09:27 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO ResourceUtils: ==============================================================
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:09:27 ERROR 
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO ResourceUtils: ==============================================================
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO Utils: Successfully started service 'sparkDriver' on port 44607.
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-779bd2ad-f3bd-481f-94b5-a27ccb450a03
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:09:27 ERROR 20/08/23 21:09:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:09:28 ERROR 20/08/23 21:09:28 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40751.
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO NettyBlockTransferService: Server created on 172.28.187.71:40751
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 40751, None)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:40751 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 40751, None)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 40751, None)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 40751, None)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:40751 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:9
2020.08.23 21:09:28 ERROR Exception in thread "main" org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/home/cyfer/scala/week1/resources/wikipedia/wikipedia.dat
2020.08.23 21:09:28 ERROR 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)
2020.08.23 21:09:28 ERROR 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)
2020.08.23 21:09:28 ERROR 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:205)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:276)
2020.08.23 21:09:28 ERROR 	at scala.Option.getOrElse(Option.scala:189)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:272)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:276)
2020.08.23 21:09:28 ERROR 	at scala.Option.getOrElse(Option.scala:189)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:272)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:276)
2020.08.23 21:09:28 ERROR 	at scala.Option.getOrElse(Option.scala:189)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:272)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2020.08.23 21:09:28 ERROR 	at org.apache.spark.rdd.RDD.count(RDD.scala:1227)
2020.08.23 21:09:28 ERROR 	at WordCount$.delayedEndpoint$WordCount$1(week1.scala:10)
2020.08.23 21:09:28 ERROR 	at WordCount$delayedInit$body.apply(week1.scala:3)
2020.08.23 21:09:28 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2020.08.23 21:09:28 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2020.08.23 21:09:28 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2020.08.23 21:09:28 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2020.08.23 21:09:28 ERROR 	at scala.collection.immutable.List.foreach(List.scala:431)
2020.08.23 21:09:28 ERROR 	at scala.App.main(App.scala:80)
2020.08.23 21:09:28 ERROR 	at scala.App.main$(App.scala:78)
2020.08.23 21:09:28 ERROR 	at WordCount$.main(week1.scala:4)
2020.08.23 21:09:28 ERROR 	at WordCount.main(week1.scala)
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManager: BlockManager stopped
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:09:28 ERROR 20/08/23 21:09:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-dbfc1489-9b5c-4f7b-bc61-e9e5b6e69c76
2020.08.23 21:09:29 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:10:34 INFO  compiling week1 (1 scala source)
2020.08.23 21:10:34 INFO  time: compiled week1 in 0.44s
2020.08.23 21:10:35 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:10:35 INFO  Listening for transport dt_socket at address: 44313
2020.08.23 21:10:35 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:10:35 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:10:35 INFO  Trying to attach to remote debuggee VM localhost:44313 .
2020.08.23 21:10:35 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:10:35 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:10:35 ERROR 20/08/23 21:10:36 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:10:35 ERROR 20/08/23 21:10:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO ResourceUtils: ==============================================================
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:10:37 ERROR 
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO ResourceUtils: ==============================================================
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO Utils: Successfully started service 'sparkDriver' on port 46069.
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:10:37 ERROR 20/08/23 21:10:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-65951e8f-1b45-4570-aa20-b18aea43a36e
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44139.
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO NettyBlockTransferService: Server created on 172.28.187.71:44139
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 44139, None)
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:44139 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 44139, None)
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 44139, None)
2020.08.23 21:10:37 ERROR 20/08/23 21:10:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 44139, None)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:44139 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:38 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:8
2020.08.23 21:10:38 ERROR 20/08/23 21:10:38 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KiB, free 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:44139 (size: 2.5 KiB, free: 3.2 GiB)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 679 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 682 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 681 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 699 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 23 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 0.780 s
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 0.820614 s
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:10:38 ERROR 20/08/23 21:10:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO BlockManager: BlockManager stopped
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:10:39 ERROR 20/08/23 21:10:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-ca96eb15-9a99-4bbb-bcdb-7d2ae94a6a3f
2020.08.23 21:10:39 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:12:56 INFO  compiling week1 (1 scala source)
2020.08.23 21:12:56 INFO  time: compiled week1 in 0.47s
2020.08.23 21:12:59 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:12:59 INFO  Listening for transport dt_socket at address: 37993
2020.08.23 21:12:59 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:13:00 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:12:59 INFO  Trying to attach to remote debuggee VM localhost:37993 .
2020.08.23 21:12:59 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:12:59 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:12:59 ERROR 20/08/23 21:13:00 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:12:59 ERROR 20/08/23 21:13:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:13:01 ERROR 20/08/23 21:13:01 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO ResourceUtils: ==============================================================
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:13:01 ERROR 
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO ResourceUtils: ==============================================================
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO Utils: Successfully started service 'sparkDriver' on port 42277.
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-58dc888f-9a2b-4b77-b62f-f5893250819d
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:13:01 ERROR 20/08/23 21:13:02 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34003.
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO NettyBlockTransferService: Server created on 172.28.187.71:34003
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 34003, None)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:34003 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 34003, None)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 34003, None)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 34003, None)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:34003 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:8
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KiB, free 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:34003 (size: 2.5 KiB, free: 3.2 GiB)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:13:02 ERROR 20/08/23 21:13:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 639 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 628 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 630 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 631 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 22 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 0.720 s
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 0.755667 s
2020.08.23 21:13:04 INFO  284
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO BlockManager: BlockManager stopped
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:13:04 ERROR 20/08/23 21:13:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-a398ac17-d28f-40ff-8e39-4f95a093f182
2020.08.23 21:13:04 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:13:17 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:13:17 INFO  Listening for transport dt_socket at address: 41165
2020.08.23 21:13:17 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:13:17 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:13:17 INFO  Trying to attach to remote debuggee VM localhost:41165 .
2020.08.23 21:13:17 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:13:17 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:13:17 ERROR 20/08/23 21:13:18 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:13:17 ERROR 20/08/23 21:13:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO ResourceUtils: ==============================================================
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:13:19 ERROR 
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO ResourceUtils: ==============================================================
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO Utils: Successfully started service 'sparkDriver' on port 44331.
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-49827ca1-e167-4b7d-9a80-6def427dc77f
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:13:19 ERROR 20/08/23 21:13:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:13:19 ERROR 20/08/23 21:13:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33517.
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO NettyBlockTransferService: Server created on 172.28.187.71:33517
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 33517, None)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:33517 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 33517, None)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 33517, None)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 33517, None)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:33517 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:8
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KiB, free 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:33517 (size: 2.5 KiB, free: 3.2 GiB)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:13:20 ERROR 20/08/23 21:13:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1047 bytes result sent to driver
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1047 bytes result sent to driver
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 647 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 647 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 647 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 662 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 22 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 0.738 s
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 0.778152 s
2020.08.23 21:13:21 INFO  284
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO BlockManager: BlockManager stopped
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:13:21 ERROR 20/08/23 21:13:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-4fa3c802-0863-4a31-ad44-6a18b207d188
2020.08.23 21:13:21 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:17:35 INFO  compiling week1 (1 scala source)
2020.08.23 21:17:35 INFO  time: compiled week1 in 0.43s
2020.08.23 21:17:36 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:17:36 INFO  Listening for transport dt_socket at address: 43733
2020.08.23 21:17:36 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:17:36 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:17:36 INFO  Trying to attach to remote debuggee VM localhost:43733 .
2020.08.23 21:17:36 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:17:36 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:17:36 ERROR 20/08/23 21:17:37 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:17:36 ERROR 20/08/23 21:17:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO ResourceUtils: ==============================================================
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:17:38 ERROR 
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO ResourceUtils: ==============================================================
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:17:38 ERROR 20/08/23 21:17:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO Utils: Successfully started service 'sparkDriver' on port 46809.
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-95d9aec2-11d4-4f07-95e9-7cadbd703d77
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:17:38 ERROR 20/08/23 21:17:39 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43615.
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO NettyBlockTransferService: Server created on 172.28.187.71:43615
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 43615, None)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:43615 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 43615, None)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 43615, None)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 43615, None)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:43615 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:8
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KiB, free 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:43615 (size: 2.5 KiB, free: 3.2 GiB)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:17:39 ERROR 20/08/23 21:17:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 653 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 655 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 657 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 671 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 20 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 0.744 s
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:17:40 ERROR 20/08/23 21:17:40 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 0.782931 s
2020.08.23 21:17:40 INFO  284
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO BlockManager: BlockManager stopped
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:18:40 ERROR 20/08/23 21:18:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-79cb6f3f-baf4-473b-aef1-67fcd1a807df
2020.08.23 21:18:41 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:19:04 INFO  compiling week1 (1 scala source)
2020.08.23 21:19:04 INFO  time: compiled week1 in 0.47s
2020.08.23 21:19:34 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:19:35 INFO  Listening for transport dt_socket at address: 46877
2020.08.23 21:19:34 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:19:35 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:19:35 INFO  Trying to attach to remote debuggee VM localhost:46877 .
2020.08.23 21:19:35 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:19:35 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:19:35 ERROR 20/08/23 21:19:35 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:19:35 ERROR 20/08/23 21:19:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:19:36 ERROR 20/08/23 21:19:36 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO ResourceUtils: ==============================================================
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:19:36 ERROR 
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO ResourceUtils: ==============================================================
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO Utils: Successfully started service 'sparkDriver' on port 42403.
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4c0a8839-9670-4fd1-ac2b-eaf3e9d3fbb9
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:19:36 ERROR 20/08/23 21:19:37 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:19:37 ERROR 20/08/23 21:19:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37137.
2020.08.23 21:19:37 ERROR 20/08/23 21:19:37 INFO NettyBlockTransferService: Server created on 172.28.187.71:37137
2020.08.23 21:19:37 ERROR 20/08/23 21:19:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:19:37 ERROR 20/08/23 21:19:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 37137, None)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:37137 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 37137, None)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 37137, None)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 37137, None)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:37137 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:8
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KiB, free 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:37137 (size: 2.5 KiB, free: 3.2 GiB)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:19:37 ERROR 20/08/23 21:19:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1047 bytes result sent to driver
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 634 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 637 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 639 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 654 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 23 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 0.730 s
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:19:39 ERROR 20/08/23 21:19:39 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 0.773930 s
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:19:39 INFO  284
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO BlockManager: BlockManager stopped
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:20:39 ERROR 20/08/23 21:20:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-3178bddd-3211-4190-86b1-eda8103b59fb
2020.08.23 21:20:39 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:25:48 INFO  compiling week1 (1 scala source)
2020.08.23 21:25:48 INFO  time: compiled week1 in 0.43s
2020.08.23 21:32:42 INFO  compiling week1 (1 scala source)
2020.08.23 21:32:42 INFO  time: compiled week1 in 0.5s
2020.08.23 21:35:19 INFO  compiling week1 (1 scala source)
2020.08.23 21:35:19 INFO  time: compiled week1 in 59ms
2020.08.23 21:36:16 INFO  compiling week1 (1 scala source)
2020.08.23 21:36:16 INFO  time: compiled week1 in 72ms
2020.08.23 21:36:22 INFO  compiling week1 (1 scala source)
2020.08.23 21:36:22 INFO  time: compiled week1 in 76ms
2020.08.23 21:37:00 INFO  compiling week1 (1 scala source)
2020.08.23 21:37:00 INFO  time: compiled week1 in 0.49s
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in org.apache.spark.rdd.RDD[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 169, 169, 180)
2020.08.23 21:38:35 INFO  compiling week1 (1 scala source)
2020.08.23 21:38:35 INFO  time: compiled week1 in 0.48s
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in List[<error>]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 146, 146, 541)
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in List[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 146, 146, 158)
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in List[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 146, 146, 158)
2020.08.23 21:38:49 INFO  compiling week1 (1 scala source)
2020.08.23 21:38:49 INFO  time: compiled week1 in 79ms
2020.08.23 21:41:13 INFO  compiling week1 (1 scala source)
2020.08.23 21:41:13 INFO  time: compiled week1 in 0.52s
Aug 23, 2020 9:41:25 PM scala.meta.internal.pc.CompletionProvider expected$1
WARNING: String index out of range: -1
2020.08.23 21:41:28 INFO  compiling week1 (1 scala source)
2020.08.23 21:41:28 INFO  time: compiled week1 in 0.49s
2020.08.23 21:49:00 INFO  compiling week1 (1 scala source)
2020.08.23 21:49:00 INFO  time: compiled week1 in 0.52s
2020.08.23 21:49:23 INFO  compiling week1 (1 scala source)
2020.08.23 21:49:23 INFO  time: compiled week1 in 0.48s
2020.08.23 21:51:36 INFO  compiling week1 (1 scala source)
2020.08.23 21:51:36 INFO  time: compiled week1 in 64ms
2020.08.23 21:52:07 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:07 INFO  time: compiled week1 in 84ms
2020.08.23 21:52:19 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:19 INFO  time: compiled week1 in 53ms
2020.08.23 21:52:26 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:26 INFO  time: compiled week1 in 56ms
2020.08.23 21:52:33 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:33 INFO  time: compiled week1 in 52ms
2020.08.23 21:52:41 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:41 INFO  time: compiled week1 in 0.4s
2020.08.23 21:52:44 INFO  compiling week1 (1 scala source)
2020.08.23 21:52:44 INFO  time: compiled week1 in 76ms
2020.08.23 21:53:08 INFO  compiling week1 (1 scala source)
2020.08.23 21:53:08 INFO  time: compiled week1 in 85ms
2020.08.23 21:53:32 INFO  compiling week1 (1 scala source)
2020.08.23 21:53:32 INFO  time: compiled week1 in 91ms
2020.08.23 21:53:53 INFO  compiling week1 (1 scala source)
2020.08.23 21:53:53 INFO  time: compiled week1 in 53ms
2020.08.23 21:54:01 INFO  compiling week1 (1 scala source)
2020.08.23 21:54:01 INFO  time: compiled week1 in 78ms
Aug 23, 2020 9:54:04 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 9:54:04 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 9:54:04 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 9:54:04 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020.08.23 21:54:05 INFO  compiling week1 (1 scala source)
2020.08.23 21:54:05 INFO  time: compiled week1 in 59ms
2020.08.23 21:54:07 INFO  compiling week1 (1 scala source)
2020.08.23 21:54:07 INFO  time: compiled week1 in 57ms
2020.08.23 21:54:18 INFO  compiling week1 (1 scala source)
2020.08.23 21:54:18 INFO  time: compiled week1 in 81ms
2020.08.23 21:55:01 INFO  compiling week1 (1 scala source)
2020.08.23 21:55:01 INFO  time: compiled week1 in 0.53s
2020.08.23 21:55:30 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:30 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:30 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:30 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:41 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:41 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:41 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:41 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:43 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:43 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:43 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:43 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:9: stale bloop warning: enclosing method occurencesOfLang has result type Unit: return value of type Long discarded
        return langCount
        ^^^^^^^^^^^^^^^^
2020.08.23 21:55:44 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:8:16: stale bloop warning: a pure expression does nothing in statement position
        return langCount
               ^^^^^^^^^
2020.08.23 21:55:48 INFO  compiling week1 (1 scala source)
2020.08.23 21:55:48 INFO  time: compiled week1 in 0.49s
2020.08.23 21:55:50 INFO  compiling week1 (1 scala source)
2020.08.23 21:55:50 INFO  time: compiled week1 in 0.52s
2020.08.23 21:55:52 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:55:53 INFO  Listening for transport dt_socket at address: 40387
2020.08.23 21:55:52 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:55:53 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:55:53 INFO  Trying to attach to remote debuggee VM localhost:40387 .
2020.08.23 21:55:53 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:55:53 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:55:53 ERROR 20/08/23 21:55:53 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:55:53 ERROR 20/08/23 21:55:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:55:54 ERROR 20/08/23 21:55:54 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO ResourceUtils: ==============================================================
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:55:54 ERROR 
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO ResourceUtils: ==============================================================
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO Utils: Successfully started service 'sparkDriver' on port 34499.
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-24e521f7-1b1b-4225-bee0-e0ba69490ba0
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:55:54 ERROR 20/08/23 21:55:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:55:55 ERROR 20/08/23 21:55:55 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40919.
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO NettyBlockTransferService: Server created on 172.28.187.71:40919
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 40919, None)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:40919 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 40919, None)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 40919, None)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 40919, None)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:40919 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:17
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:40919 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:55:55 ERROR 20/08/23 21:55:56 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:40919 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.1 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:40919 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:40919 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:40919 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1188 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1194 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1215 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:40919 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1208 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 44 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:55:57 ERROR 20/08/23 21:55:57 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.303 s
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.345778 s
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:40919 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:55:57 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 181 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 182 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 200 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 961 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 27 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 209 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.219 s
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.226118 s
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:40919 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 162 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 165 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 170 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 175 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 25 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.194 s
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.199893 s
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:40919 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 143 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 151 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 164 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 164 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 24 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.177 s
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 21:55:58 ERROR 20/08/23 21:55:58 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.182732 s
2020.08.23 21:55:58 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 21:55:58 INFO  ()
2020.08.23 21:55:58 INFO  ()
2020.08.23 21:55:58 INFO  ()
2020.08.23 21:55:58 INFO  ()
2020.08.23 21:55:58 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO MemoryStore: MemoryStore cleared
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO BlockManager: BlockManager stopped
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 21:56:58 ERROR 20/08/23 21:56:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-adf4ea2c-b344-4473-8c85-f156248f0980
2020.08.23 21:56:58 INFO  Canceling debug proxy for [WordCount]
2020.08.23 21:59:12 INFO  compiling week1 (1 scala source)
2020.08.23 21:59:12 INFO  time: compiled week1 in 0.51s
2020.08.23 21:59:18 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 21:59:18 INFO  Listening for transport dt_socket at address: 45781
2020.08.23 21:59:18 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 21:59:18 INFO  Starting debug proxy for [WordCount]
2020.08.23 21:59:18 INFO  Trying to attach to remote debuggee VM localhost:45781 .
2020.08.23 21:59:18 INFO  Attaching to debuggee VM succeeded.
2020.08.23 21:59:18 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 21:59:18 ERROR 20/08/23 21:59:18 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 21:59:18 ERROR 20/08/23 21:59:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO ResourceUtils: ==============================================================
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 21:59:20 ERROR 
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO ResourceUtils: ==============================================================
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkContext: Submitted application: Abusei
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO Utils: Successfully started service 'sparkDriver' on port 41791.
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5efb13dc-e1a0-4445-a033-e5c2a540d6bb
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 21:59:20 ERROR 20/08/23 21:59:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 21:59:20 ERROR 20/08/23 21:59:21 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 21:59:20 ERROR 20/08/23 21:59:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34635.
2020.08.23 21:59:20 ERROR 20/08/23 21:59:21 INFO NettyBlockTransferService: Server created on 172.28.187.71:34635
2020.08.23 21:59:20 ERROR 20/08/23 21:59:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 34635, None)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:34635 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 34635, None)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 34635, None)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 34635, None)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:34635 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:16
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:34635 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 21:59:21 ERROR 20/08/23 21:59:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:34635 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.1 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:34635 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:34635 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:34635 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1114 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1116 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1130 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1120 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:34635 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 43 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.231 s
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.277944 s
2020.08.23 21:59:22 ERROR 20/08/23 21:59:22 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:34635 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 173 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 173 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 184 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 190 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 961 bytes result sent to driver
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 26 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.210 s
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.216594 s
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:34635 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 21:59:22 ERROR 20/08/23 21:59:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 153 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 166 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 167 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 26 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 180 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.188 s
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.192990 s
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Missing parents: List()
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:34635 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 143 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 149 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 160 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 159 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 25 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.177 s
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 21:59:23 ERROR 20/08/23 21:59:23 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.181820 s
2020.08.23 21:59:23 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 21:59:23 INFO  ()
2020.08.23 21:59:23 INFO  ()
2020.08.23 21:59:23 INFO  ()
2020.08.23 21:59:23 INFO  ()
2020.08.23 21:59:23 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO MemoryStore: MemoryStore cleared
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO BlockManager: BlockManager stopped
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 22:00:23 ERROR 20/08/23 22:00:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-1598fd4b-a63f-4e4e-8424-39052bf8b3fc
2020.08.23 22:00:23 INFO  Canceling debug proxy for [WordCount]
2020.08.23 22:01:30 INFO  compiling week1 (1 scala source)
2020.08.23 22:01:30 INFO  time: compiled week1 in 0.5s
Aug 23, 2020 10:01:35 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:35 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:36 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:36 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020.08.23 22:01:43 INFO  compiling week1 (1 scala source)
2020.08.23 22:01:43 INFO  time: compiled week1 in 0.5s
Aug 23, 2020 10:01:48 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:48 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:48 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:01:48 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020.08.23 22:01:49 INFO  compiling week1 (1 scala source)
2020.08.23 22:01:49 INFO  time: compiled week1 in 75ms
2020.08.23 22:01:51 INFO  compiling week1 (1 scala source)
2020.08.23 22:01:51 INFO  time: compiled week1 in 78ms
2020.08.23 22:02:37 INFO  compiling week1 (1 scala source)
2020.08.23 22:02:37 INFO  time: compiled week1 in 72ms
2020.08.23 22:02:44 INFO  compiling week1 (1 scala source)
2020.08.23 22:02:44 INFO  time: compiled week1 in 97ms
2020.08.23 22:02:54 INFO  compiling week1 (1 scala source)
2020.08.23 22:02:54 INFO  time: compiled week1 in 73ms
2020.08.23 22:03:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 22:03:08 INFO  Listening for transport dt_socket at address: 42319
2020.08.23 22:03:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 22:03:08 INFO  Starting debug proxy for [WordCount]
2020.08.23 22:03:08 INFO  Trying to attach to remote debuggee VM localhost:42319 .
2020.08.23 22:03:08 INFO  Attaching to debuggee VM succeeded.
2020.08.23 22:03:08 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 22:03:08 ERROR 20/08/23 22:03:08 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 22:03:08 ERROR 20/08/23 22:03:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO ResourceUtils: ==============================================================
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 22:03:10 ERROR 
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO ResourceUtils: ==============================================================
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkContext: Submitted application: Abusei
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO Utils: Successfully started service 'sparkDriver' on port 38109.
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13483d00-5c20-476d-afe8-7bb05cc9db83
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41313.
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO NettyBlockTransferService: Server created on 172.28.187.71:41313
2020.08.23 22:03:10 ERROR 20/08/23 22:03:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 22:03:10 ERROR 20/08/23 22:03:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 41313, None)
2020.08.23 22:03:10 ERROR 20/08/23 22:03:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:41313 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 41313, None)
2020.08.23 22:03:10 ERROR 20/08/23 22:03:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 41313, None)
2020.08.23 22:03:10 ERROR 20/08/23 22:03:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 41313, None)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:41313 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:17
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:41313 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:41313 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.1 GiB)
2020.08.23 22:03:11 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:41313 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:41313 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:41313 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1180 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1183 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1197 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1183 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:41313 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 52 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.304 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.345922 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:41313 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:12 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 178 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 218 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 221 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 46 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 229 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.241 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.247580 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:41313 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 136 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 152 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 25 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 961 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 172 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 174 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.182 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.187546 s
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:41313 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.28.187.71:41313 in memory (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 163 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 22:03:12 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 166 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 179 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 23 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 187 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.196 s
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 22:03:13 ERROR 20/08/23 22:03:13 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.201753 s
2020.08.23 22:03:13 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 22:03:13 INFO  ()
2020.08.23 22:03:13 INFO  ()
2020.08.23 22:03:13 INFO  ()
2020.08.23 22:03:13 INFO  ()
2020.08.23 22:03:13 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in org.apache.spark.rdd.RDD[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 167, 167, 178)
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO MemoryStore: MemoryStore cleared
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO BlockManager: BlockManager stopped
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 22:04:13 ERROR 20/08/23 22:04:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-abb3a1db-2d62-45e2-9a7c-d58d8bd1c7c2
2020.08.23 22:04:13 INFO  Canceling debug proxy for [WordCount]
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in org.apache.spark.rdd.RDD[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 167, 167, 178)
Aug 23, 2020 10:04:44 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:44 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:44 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:45 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:45 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:45 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Aug 23, 2020 10:04:45 PM scala.meta.internal.pc.completions.Completions completionPosition
SEVERE: null
java.lang.NullPointerException
	at scala.meta.internal.pc.completions.OverrideCompletions$OverrideCompletion.<init>(OverrideCompletions.scala:46)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe(Completions.scala:500)
	at scala.meta.internal.pc.completions.Completions.completionPositionUnsafe$(Completions.scala:409)
	at scala.meta.internal.pc.MetalsGlobal.completionPositionUnsafe(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.completions.Completions.completionPosition(Completions.scala:401)
	at scala.meta.internal.pc.completions.Completions.completionPosition$(Completions.scala:386)
	at scala.meta.internal.pc.MetalsGlobal.completionPosition(MetalsGlobal.scala:29)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:444)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:57)
	at scala.meta.internal.pc.ScalaPresentationCompiler.$anonfun$complete$1(ScalaPresentationCompiler.scala:184)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:137)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$withInterruptableCompiler$1(CompilerAccess.scala:87)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:197)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:103)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020.08.23 22:04:48 INFO  compiling week1 (1 scala source)
2020.08.23 22:04:48 INFO  time: compiled week1 in 75ms
something's wrong: no file:///home/cyfer/scala/week1/src/main/scala/week1.scala in org.apache.spark.rdd.RDD[String]RangePosition(file:///home/cyfer/scala/week1/src/main/scala/week1.scala, 167, 167, 178)
2020.08.23 22:05:14 INFO  compiling week1 (1 scala source)
2020.08.23 22:05:14 INFO  time: compiled week1 in 75ms
2020.08.23 22:05:14 INFO  compiling week1 (1 scala source)
2020.08.23 22:05:14 INFO  time: compiled week1 in 35ms
2020.08.23 22:05:18 INFO  compiling week1 (1 scala source)
2020.08.23 22:05:18 INFO  time: compiled week1 in 71ms
2020.08.23 22:06:21 INFO  compiling week1 (1 scala source)
2020.08.23 22:06:21 INFO  time: compiled week1 in 0.5s
2020.08.23 22:06:28 INFO  compiling week1 (1 scala source)
2020.08.23 22:06:28 INFO  time: compiled week1 in 0.51s
2020.08.23 22:06:49 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 22:06:49 INFO  Listening for transport dt_socket at address: 39735
2020.08.23 22:06:49 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 22:06:50 INFO  Starting debug proxy for [WordCount]
2020.08.23 22:06:49 INFO  Trying to attach to remote debuggee VM localhost:39735 .
2020.08.23 22:06:49 INFO  Attaching to debuggee VM succeeded.
2020.08.23 22:06:49 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 22:06:49 ERROR 20/08/23 22:06:50 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 22:06:49 ERROR 20/08/23 22:06:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 22:06:51 ERROR 20/08/23 22:06:51 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO ResourceUtils: ==============================================================
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 22:06:51 ERROR 
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO ResourceUtils: ==============================================================
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkContext: Submitted application: Abusei
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO Utils: Successfully started service 'sparkDriver' on port 44395.
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0d622490-6c8b-4c35-90fd-330f0f4dda5e
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37677.
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO NettyBlockTransferService: Server created on 172.28.187.71:37677
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 22:06:51 ERROR 20/08/23 22:06:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 37677, None)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:52 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:37677 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 37677, None)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 37677, None)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 37677, None)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:37677 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:17
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:37677 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 22:06:52 ERROR 20/08/23 22:06:53 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:37677 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.1 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:37677 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:37677 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:37677 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1047 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1047 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1047 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1106 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1108 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1109 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1124 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:37677 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 41 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.223 s
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.266612 s
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:37677 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:54 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 169 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 174 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 176 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 180 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 961 bytes result sent to driver
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 24 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.204 s
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.210789 s
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:37677 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:06:54 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 163 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 165 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 168 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 170 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 25 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.197 s
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.202302 s
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Missing parents: List()
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:37677 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 135 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 152 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 156 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 23 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 170 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.180 s
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 22:06:55 ERROR 20/08/23 22:06:55 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.185780 s
2020.08.23 22:06:55 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 22:06:55 INFO  387
2020.08.23 22:06:55 INFO  580
2020.08.23 22:06:55 INFO  128
2020.08.23 22:06:55 INFO  2031
2020.08.23 22:06:55 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO MemoryStore: MemoryStore cleared
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO BlockManager: BlockManager stopped
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 22:07:55 ERROR 20/08/23 22:07:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-a07d16b1-e6e0-4894-a915-51500412a6b8
2020.08.23 22:07:55 INFO  Canceling debug proxy for [WordCount]
2020.08.23 22:22:14 INFO  compiling week1 (1 scala source)
2020.08.23 22:22:14 INFO  time: compiled week1 in 0.59s
2020.08.23 23:04:26 INFO  compiling week1 (1 scala source)
2020.08.23 23:04:26 INFO  time: compiled week1 in 0.61s
2020.08.23 23:04:28 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 23:04:28 INFO  Listening for transport dt_socket at address: 44975
2020.08.23 23:04:28 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 23:04:29 INFO  Starting debug proxy for [WordCount]
2020.08.23 23:04:28 INFO  Trying to attach to remote debuggee VM localhost:44975 .
2020.08.23 23:04:28 INFO  Attaching to debuggee VM succeeded.
2020.08.23 23:04:28 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 23:04:28 ERROR 20/08/23 23:04:29 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 23:04:28 ERROR 20/08/23 23:04:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 23:04:30 ERROR 20/08/23 23:04:30 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO ResourceUtils: ==============================================================
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 23:04:30 ERROR 
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO ResourceUtils: ==============================================================
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkContext: Submitted application: Abusei
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO Utils: Successfully started service 'sparkDriver' on port 46135.
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bf88d7c5-38b2-4602-8088-f61cf1926735
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 23:04:30 ERROR 20/08/23 23:04:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43927.
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO NettyBlockTransferService: Server created on 172.28.187.71:43927
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 43927, None)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:43927 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 43927, None)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 43927, None)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 43927, None)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:43927 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:17
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:43927 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 23:04:31 ERROR 20/08/23 23:04:32 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.0 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:43927 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:43927 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:43927 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:43927 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1176 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1179 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1178 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1194 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:43927 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 47 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.300 s
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.350722 s
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:43927 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 23:04:33 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:04:33 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:04:33 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:04:33 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 177 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 181 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 199 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 200 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 961 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 28 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.217 s
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.223713 s
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:43927 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 158 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 162 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 170 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 170 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 27 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.194 s
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.200177 s
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:43927 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 152 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 167 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 167 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 169 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 28 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.190 s
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 23:04:34 ERROR 20/08/23 23:04:34 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.194562 s
2020.08.23 23:04:34 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 23:04:34 INFO  387
2020.08.23 23:04:34 INFO  580
2020.08.23 23:04:34 INFO  128
2020.08.23 23:04:34 INFO  2031
2020.08.23 23:04:34 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 23:05:08 INFO  compiling week1 (1 scala source)
2020.08.23 23:05:08 INFO  time: compiled week1 in 0.13s
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:19:46: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val scalaWords = occurencesOfLang("scala", input)
                                             ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:20:48: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val pythonWords = occurencesOfLang("python", input)
                                               ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:21:50: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val haskellWords = occurencesOfLang("haskell", input)
                                                 ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:22:44: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val javaWords = occurencesOfLang("java", input)
                                           ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:19:46: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val scalaWords = occurencesOfLang("scala", input)
                                             ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:20:48: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val pythonWords = occurencesOfLang("python", input)
                                               ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:21:50: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val haskellWords = occurencesOfLang("haskell", input)
                                                 ^^^^^
2020.08.23 23:05:14 INFO  /home/cyfer/scala/week1/src/main/scala/week1.scala:22:44: stale bloop error: too many arguments (2) for method occurencesOfLang: (lang: String)Long
  val javaWords = occurencesOfLang("java", input)
                                           ^^^^^
2020.08.23 23:05:34 INFO  compiling week1 (1 scala source)
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO MemoryStore: MemoryStore cleared
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO BlockManager: BlockManager stopped
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 23:05:34 ERROR 20/08/23 23:05:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e9a3902-5c09-49ba-8cc5-4940be576445
2020.08.23 23:05:34 INFO  Canceling debug proxy for [WordCount]
2020.08.23 23:05:34 INFO  time: compiled week1 in 0.61s
2020.08.23 23:07:01 INFO  compiling week1 (1 scala source)
2020.08.23 23:07:01 INFO  time: compiled week1 in 0.61s
2020.08.23 23:08:11 INFO  compiling week1 (1 scala source)
2020.08.23 23:08:11 INFO  time: compiled week1 in 0.57s
2020.08.23 23:09:02 INFO  compiling week1 (1 scala source)
2020.08.23 23:09:02 INFO  time: compiled week1 in 0.62s
2020.08.23 23:09:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-server.trace.json
2020.08.23 23:09:08 INFO  Listening for transport dt_socket at address: 33705
2020.08.23 23:09:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/cyfer/.cache/metals/dap-client.trace.json
2020.08.23 23:09:09 INFO  Starting debug proxy for [WordCount]
2020.08.23 23:09:08 INFO  Trying to attach to remote debuggee VM localhost:33705 .
2020.08.23 23:09:08 INFO  Attaching to debuggee VM succeeded.
2020.08.23 23:09:08 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2020.08.23 23:09:08 ERROR 20/08/23 23:09:09 WARN Utils: Your hostname, DESKTOP-QN8V4GV resolves to a loopback address: 127.0.1.1; using 172.28.187.71 instead (on interface eth0)
2020.08.23 23:09:08 ERROR 20/08/23 23:09:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkContext: Running Spark version 3.0.0
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO ResourceUtils: ==============================================================
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO ResourceUtils: Resources for spark.driver:
2020.08.23 23:09:11 ERROR 
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO ResourceUtils: ==============================================================
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkContext: Submitted application: Abusei
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SecurityManager: Changing view acls to: cyfer
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SecurityManager: Changing modify acls to: cyfer
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SecurityManager: Changing view acls groups to: 
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SecurityManager: Changing modify acls groups to: 
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cyfer); groups with view permissions: Set(); users  with modify permissions: Set(cyfer); groups with modify permissions: Set()
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO Utils: Successfully started service 'sparkDriver' on port 37353.
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkEnv: Registering MapOutputTracker
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkEnv: Registering BlockManagerMaster
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a4b23243-f497-4821-acae-0006a59ff9c0
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO MemoryStore: MemoryStore started with capacity 3.2 GiB
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO SparkEnv: Registering OutputCommitCoordinator
2020.08.23 23:09:11 ERROR 20/08/23 23:09:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2020.08.23 23:09:11 ERROR 20/08/23 23:09:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.28.187.71:4040
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO Executor: Starting executor ID driver on host 172.28.187.71
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43617.
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO NettyBlockTransferService: Server created on 172.28.187.71:43617
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.187.71, 43617, None)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.187.71:43617 with 3.2 GiB RAM, BlockManagerId(driver, 172.28.187.71, 43617, None)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.187.71, 43617, None)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.187.71, 43617, None)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.5 KiB, free 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.187.71:43617 (size: 23.4 KiB, free: 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO SparkContext: Created broadcast 0 from textFile at week1.scala:17
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO FileInputFormat: Total input paths to process : 1
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Got job 0 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Final stage: ResultStage 0 (count at week1.scala:9)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.6 KiB, free 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 3.2 GiB)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:12 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:13 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:13 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
2020.08.23 23:09:12 ERROR 20/08/23 23:09:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:0+33554432
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:33554432+33554432
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:67108864+33554432
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:100663296+33554432
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO MemoryStore: Block rdd_1_2 stored as values in memory (estimated size 64.0 MiB, free 3.1 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO BlockManagerInfo: Added rdd_1_2 in memory on 172.28.187.71:43617 (size: 64.0 MiB, free: 3.1 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO MemoryStore: Block rdd_1_3 stored as values in memory (estimated size 41.3 MiB, free 3.1 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO BlockManagerInfo: Added rdd_1_3 in memory on 172.28.187.71:43617 (size: 41.3 MiB, free: 3.1 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 55.2 MiB, free 3.0 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO BlockManagerInfo: Added rdd_1_1 in memory on 172.28.187.71:43617 (size: 55.2 MiB, free: 3.0 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 61.1 MiB, free 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:13 INFO BlockManagerInfo: Added rdd_1_0 in memory on 172.28.187.71:43617 (size: 61.1 MiB, free: 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1004 bytes result sent to driver
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1004 bytes result sent to driver
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1212 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1213 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO HadoopRDD: Input split: file:/home/cyfer/scala/week1/src/main/resources/wikipedia/wikipedia.dat:134217728+4929995
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1004 bytes result sent to driver
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1004 bytes result sent to driver
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1218 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1237 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block rdd_1_4 stored as values in memory (estimated size 9.4 MiB, free 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManagerInfo: Added rdd_1_4 in memory on 172.28.187.71:43617 (size: 9.4 MiB, free: 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 961 bytes result sent to driver
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 47 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: ResultStage 0 (count at week1.scala:9) finished in 1.338 s
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 0 finished: count at week1.scala:9, took 1.384652 s
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Got job 1 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Final stage: ResultStage 1 (count at week1.scala:9)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:13 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 188 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 193 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 193 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 197 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 24 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: ResultStage 1 (count at week1.scala:9) finished in 0.221 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 1 finished: count at week1.scala:9, took 0.228257 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Got job 2 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Final stage: ResultStage 2 (count at week1.scala:9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 173 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 176 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 185 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 185 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 26 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: ResultStage 2 (count at week1.scala:9) finished in 0.207 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 2 finished: count at week1.scala:9, took 0.213819 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Got job 3 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Final stage: ResultStage 3 (count at week1.scala:9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 148 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 154 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 155 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 163 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 28 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: ResultStage 3 (count at week1.scala:9) finished in 0.186 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Job 3 finished: count at week1.scala:9, took 0.192522 s
2020.08.23 23:09:14 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 23:09:14 INFO  (scala,387)
2020.08.23 23:09:14 INFO  (python,580)
2020.08.23 23:09:14 INFO  (haskell,128)
2020.08.23 23:09:14 INFO  (java,2031)
2020.08.23 23:09:14 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Got job 4 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Final stage: ResultStage 4 (count at week1.scala:9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:14 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 162 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 165 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 190 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 198 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 1004 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 43 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: ResultStage 4 (count at week1.scala:9) finished in 0.213 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 4 finished: count at week1.scala:9, took 0.218896 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Got job 5 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Final stage: ResultStage 5 (count at week1.scala:9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[13] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 3.0 in stage 5.0 (TID 28). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 28) in 158 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 167 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 2.0 in stage 5.0 (TID 27). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 27) in 173 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 1.0 in stage 5.0 (TID 26). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 26) in 180 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 4.0 in stage 5.0 (TID 29). 961 bytes result sent to driver
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 28 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: ResultStage 5 (count at week1.scala:9) finished in 0.194 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 5 finished: count at week1.scala:9, took 0.200807 s
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Got job 6 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Final stage: ResultStage 6 (count at week1.scala:9)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[15] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 30, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 31, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 32, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 33, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 0.0 in stage 6.0 (TID 30)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 2.0 in stage 6.0 (TID 32)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 3.0 in stage 6.0 (TID 33)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO Executor: Running task 1.0 in stage 6.0 (TID 31)
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:14 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.28.187.71:43617 in memory (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 1.0 in stage 6.0 (TID 31). 1004 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 2.0 in stage 6.0 (TID 32). 1004 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 34, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 4.0 in stage 6.0 (TID 34)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 31) in 175 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 32) in 175 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 3.0 in stage 6.0 (TID 33). 1004 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 33) in 186 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 30). 1004 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 30) in 195 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 4.0 in stage 6.0 (TID 34). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 34) in 31 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: ResultStage 6 (count at week1.scala:9) finished in 0.213 s
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 6 finished: count at week1.scala:9, took 0.219482 s
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO SparkContext: Starting job: count at week1.scala:9
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Got job 7 (count at week1.scala:9) with 5 output partitions
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Final stage: ResultStage 7 (count at week1.scala:9)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Parents of final stage: List()
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Missing parents: List()
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[17] at filter at week1.scala:9), which has no missing parents
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 4.6 KiB, free 2.9 GiB)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 2.9 GiB)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.28.187.71:43617 (size: 2.6 KiB, free: 2.9 GiB)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1200
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at filter at week1.scala:9) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 35, 172.28.187.71, executor driver, partition 0, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 36, 172.28.187.71, executor driver, partition 1, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 37, 172.28.187.71, executor driver, partition 2, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 38, 172.28.187.71, executor driver, partition 3, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 1.0 in stage 7.0 (TID 36)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 2.0 in stage 7.0 (TID 37)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 0.0 in stage 7.0 (TID 35)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 3.0 in stage 7.0 (TID 38)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_2 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_1 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_0 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_3 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 2.0 in stage 7.0 (TID 37). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 1.0 in stage 7.0 (TID 36). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 39, 172.28.187.71, executor driver, partition 4, PROCESS_LOCAL, 7412 bytes)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 37) in 193 ms on 172.28.187.71 (executor driver) (1/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Running task 4.0 in stage 7.0 (TID 39)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 0.0 in stage 7.0 (TID 35). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 36) in 194 ms on 172.28.187.71 (executor driver) (2/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO BlockManager: Found block rdd_1_4 locally
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 35) in 196 ms on 172.28.187.71 (executor driver) (3/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 3.0 in stage 7.0 (TID 38). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 38) in 204 ms on 172.28.187.71 (executor driver) (4/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO Executor: Finished task 4.0 in stage 7.0 (TID 39). 961 bytes result sent to driver
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 39) in 30 ms on 172.28.187.71 (executor driver) (5/5)
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: ResultStage 7 (count at week1.scala:9) finished in 0.231 s
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
2020.08.23 23:09:15 ERROR 20/08/23 23:09:15 INFO DAGScheduler: Job 7 finished: count at week1.scala:9, took 0.236305 s
2020.08.23 23:09:15 INFO  >>>>>>>>>>>>>>>>>>>>>>>>>
2020.08.23 23:09:15 INFO  List((haskell,128), (scala,387), (python,580), (java,2031))
2020.08.23 23:09:15 INFO  <<<<<<<<<<<<<<<<<<<<<<<<<<<
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO SparkContext: Invoking stop() from shutdown hook
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO SparkUI: Stopped Spark web UI at http://172.28.187.71:4040
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO MemoryStore: MemoryStore cleared
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO BlockManager: BlockManager stopped
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO BlockManagerMaster: BlockManagerMaster stopped
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO SparkContext: Successfully stopped SparkContext
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO ShutdownHookManager: Shutdown hook called
2020.08.23 23:10:15 ERROR 20/08/23 23:10:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-eda424bf-747c-4519-8c77-2c917136b6ed
2020.08.23 23:10:15 INFO  Canceling debug proxy for [WordCount]
Aug 23, 2020 11:10:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5178
2020.08.23 23:11:45 INFO  compiling week1 (1 scala source)
2020.08.23 23:11:45 INFO  time: compiled week1 in 0.6s
2020.08.23 23:12:58 INFO  shutting down Metals
No more data in the client stdin, exiting...
No more data in the client stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
No more data in the server stdin, exiting...
